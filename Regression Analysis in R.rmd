---
title: "lab8-Regression Analysis in R"
author: "Amal Sujith"
date: "07/10/2021"
output: html_document
---



## Name: Amal Sujith

#Loading the datset

##We predict the concrete strength

```{r}
df <- read.table("realestates.csv",header=TRUE,sep=",")

df <- dplyr::sample_n(df,200)
str(df)
```
##We omit NA values

```{r}
df <- na.omit(df)
head(df)
```

#We find the correlations

```{r}
library(ggplot2)
```

```{r}
par(mar=c(2,2,2,2))
ggplot(df,aes(x=distance_to_station,y=price))+geom_point()+geom_smooth(method='lm',se=FALSE)
```

```{r}
cor(df$house.age,df$price)
```

```{r}
par(mar=c(2,2,2,2))
ggplot(df,aes(x=house.age,y=price))+geom_point()+geom_smooth(method='lm',se=FALSE)
```




```{r}
cor(df$distance_to_station,df$price)
```

```{r}
par(mar=c(2,2,2,2))
ggplot(df,aes(x=stores,y=price))+geom_point()+geom_smooth(method='lm',se=FALSE)
```

```{r}
cor(df$stores,df$price)
```

```{r}

ggplot(df,aes(x=latitude,y=price))+geom_point()+geom_smooth(method='lm',se=FALSE)
```



```{r}
cor(df$latitude,df$price)
```

```{r}
ggplot(df,aes(x=longitude,y=price))+geom_point()+geom_smooth(method='lm',se=FALSE)
```






```{r}
cor(df$longitude,df$price)
```

```{r}
## plotting b/w superplasticizer and strength
ggplot(df,aes(x=longitude,y=price))+geom_point()+geom_smooth(method='lm',se=FALSE)
```


#Inferences: The correlation of the given data is: House age: -0.18, distance to station: -0.65, stores: 0.55, latitude: 0.52 and longitude: 0.48

```{r}
#split the data into training and test data set
library(dplyr)

```

```{r}
library(tidyverse)
```


```{r}
library(caret)
```


```{r}
train_samples <- df$price %>%
  createDataPartition(p=0.8,list=FALSE)
head(train_samples)
```


```{r}
train <- df[train_samples,]
test <- df[-train_samples,]
model <- lm(price~.,data=train)
summary(model)
```

#Inference
##Here, we can see that the house.age and distance_to_station columns are most significant because they have **. So, we drop the rest columns and procedd with the first two columns.
#We Make predictions

```{r}
pred <- model %>%
  predict(df)
head(pred)
```
##Model performance

```{r}
RMSE <- RMSE(pred,df$price)
RMSE
```

```{r}
R2 <- R2(pred,df$price)
R2
```

#RSE ERROR

```{r}
sigma(model)   #RSE/mean(marketing$sales)
```

```{r}
sigma(model)*100/mean(df$price)  #percentage error
```

#Inference : Since, in the summary of the model we can see that houseage, distance from station, stores, latitude has *** i.e. their significance is more.

#Hence, we take these 5 columns and features and drop the rest of the columns.
## WE Drop columns

```{r}
df_new <- df[ -c(1,4,5,6) ]
head(df_new)
```

#split the data into training and test data set

```{r}
set.seed(123)
train_samples <- df_new$price %>%
  createDataPartition(p=0.8,list=FALSE)
head(train_samples)
```

```{r}
train2 <- df_new[train_samples,]
test2 <- df_new[-train_samples,]

model2 <- lm(price~.,data=train2)
summary(model2)
```

#Inference
##The median in model 1 was -1.478 while here the median is -1.432 which is more closer to 0 than the previous model, so this gives better performance. Also, the negetive median signifies that the data is negetively skewed. Therefore, the mean should be located towards the peak of the distribution.

#Make predictions

```{r}
pred2 <- model2 %>%
  predict(test2)
head(pred2)
```

```{r}
R2 <- R2(pred,df$price)
R2
```

#RSE ERROR

```{r}
sigma(model2)   #RSE/mean(marketing$sales)
```

```{r}
sigma(model2)*100/mean(df_new$price)  #percentage error
```

#Model performamce

```{r}
RMSE <- RMSE(pred2,test2$price)
RMSE
```

```{r}
R2 <- R2(pred2,test2$price)
R2
```
#Inference
##The R2 value of model2 is 0.46 which is less than that of model 1 which was 0.50. Therefore, this model gives better performance.

#Evaluating the normality assumption



```{r}
hist(model2$residuals)
```

```{r}
qqnorm(model2$residuals,ylab = "Residuals")
qqline(model2$residuals)
```

```{r}
plot(model2)
```
#Inference
#The model built after we drop the columns  has the same R square value. Hence there was not any signifucant difference to drop the columns.
#the column with highest correlation is distance_station. Hence we build a model only using this column.

```{r}
df2 <- df[c(3,7) ]
head(df2)
```


#split the data into training and test data set

```{r}
set.seed(123)
train_samples <- df2$price %>%
  createDataPartition(p=0.8,list=FALSE)
head(train_samples)
```

```{r}
train3 <- df2[train_samples,]
test3 <- df2[-train_samples,]

model3 <- lm(price~.,data=train3)
summary(model3)
```


#Make predictions

```{r}
pred3 <- model3 %>%
  predict(test3)
head(pred3)
```

```{r}
R2 <- R2(pred,df$price)
R2
```

#Model performamce

```{r}
RMSE <- RMSE(pred3,test3$price)
RMSE
```

```{r}
R2 <- R2(pred3,test3$price)
R2
```

#RSE ERROR

```{r}
sigma(model3)   #RSE/mean(marketing$sales)
```

```{r}
sigma(model3)*100/mean(df2$price)  #percentage error
```
```{r}
plot(model3)
```


```{r}
#confidence interval on the model parameters
confint(model)
```

```{r}
confint(model2)
```

```{r}
model3 <- lm(log(price)~distance_to_station,data=df2)
plot(model3,1)
```




